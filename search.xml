<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Various Approaches for Driver and Driving Behavior Monitoring:A Review</title>
      <link href="/posts/100001/"/>
      <url>/posts/100001/</url>
      
        <content type="html"><![CDATA[<p><strong>论文题目</strong>：驾驶员和驾驶行为监控的各种方法:综述</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>近年来，驾驶员困倦和注意力分散已经成为大量事故中的重要因素，因为它们降低了驾驶员的感知水平和决策能力，对车辆的控制能力产生了负面影响。减少这类事故的一种方法是通过监测驾驶员和驾驶行为，并在驾驶员昏昏欲睡或分心的状态下提醒驾驶员。此外，如果能够提前预测不安全的驾驶行为，这也将有助于安全驾驶。</p><p>本文将讨论对驾驶员和驾驶行为的各种监测方法以及对不安全驾驶行为的预测。</p><h3 id="驾驶员困倦的监测"><a href="#驾驶员困倦的监测" class="headerlink" title="驾驶员困倦的监测"></a>驾驶员困倦的监测</h3><p>讨论了驾驶员行为的视觉特征和非视觉特征，以及与车辆特征相关的驾驶行为。<br>视觉特征方面： 详细讨论了眼睛的相关测量、哈欠检测、面部表情等视觉特征测量<br>非视觉特征： 探索各种生理信号和利用这些信号可能的睡意检测方法。<br>基于车辆的特征： 描述了方向盘运动和横向位置的标准偏差。</p><h3 id="驾驶员的注意力分散的监测"><a href="#驾驶员的注意力分散的监测" class="headerlink" title="驾驶员的注意力分散的监测"></a>驾驶员的注意力分散的监测</h3><p>描述了头部姿势和注视方向的方法。</p><h3 id="不安全的驾驶行为的预测"><a href="#不安全的驾驶行为的预测" class="headerlink" title="不安全的驾驶行为的预测"></a>不安全的驾驶行为的预测</h3><p>解释了基于面部表情和汽车动力学的预测方法</p><h3 id="主动驾驶安全系统需要解决的几个问题"><a href="#主动驾驶安全系统需要解决的几个问题" class="headerlink" title="主动驾驶安全系统需要解决的几个问题"></a>主动驾驶安全系统需要解决的几个问题</h3><ol><li>检测睡意的混合方法</li><li>安全驾驶的驾驶上下文感知</li><li>需要公共数据集的模拟和真实驾驶条件。</li></ol><h2 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h2><p><strong>原因</strong><br>司机困倦(<strong>drowsiness</strong>)和注意力分散(<strong>distraction</strong>)是交通事故的主要原因</p><p><strong>解决方法</strong><br>设计一个框架包含两个阶段：<strong>监控和预测驾驶员和驾驶行为</strong></p><h3 id="监测困倦状态"><a href="#监测困倦状态" class="headerlink" title="监测困倦状态"></a>监测困倦状态</h3><p><strong>视觉特征</strong></p><p>驾驶员疲劳或者困倦可能与眼运动(eye movement)、面部表情(facial expression)、心跳和呼吸频率(heart and breathing rate)以及大脑活动(brain activity)的症状相关。<br>为了检测驾驶员的困倦，视觉特征(visual features)比如眼运动和面部表情是非常重要的;<br>打哈欠的测量(yawning measurement)</p><p><strong>非视觉特征</strong></p><p>非视觉特征(non-visual features),间接评估驾驶员的等级可以考虑下面几个方面：</p><ul><li>心率变异率 heart rate variability (HRV)</li><li>皮肤电反应 galvanic skin response (GSR)</li><li>传导性 conductivity</li><li>方向盘控制压力 steering-wheel grip pressure</li><li>体温 body temperature</li><li>Electroencephalogram 脑电图(EEG)和 Electro-oculogram 眼电图(EoG)提供关于困倦或情绪反应[13]的额外的心理生理学信息。</li></ul><p><strong>行为信息</strong></p><p>驾驶行为信息如方向盘运动(steering wheel movement)、车道保持(lane keeping)、加速踏板运动(acceleration pedal movement)、制动(braking)等也应被考虑来检测驾驶员是否困倦。</p><h3 id="监测注意力分散"><a href="#监测注意力分散" class="headerlink" title="监测注意力分散"></a>监测注意力分散</h3><p>视觉分心指的是“眼离路”的状态，而认知分心被描述为“脑离路”的状态。<br>为了检测驾驶员的注意力分散，需要有效地提取驾驶员 <strong>头部姿态或注视信息</strong> 。</p><p>通过仔细监测驾驶员和驾驶表现行为，可以预测 <strong>小事故和大事故(minor and major accidents)</strong></p><ul><li>Jabon et al.[15]在事故发生前的不同时间段里识别了一套驾驶员的关键面部特征，并用它们来预测小事故和大事故。这种方法对于主动驾驶安全系统的设计是非常重要的，以防止事故。</li><li>瑞士EPFL的信号处理实验室[16]通过分析面部表情和肌肉运动来检测驾驶员的分心以及情绪，这些情绪可能表明驾驶员不能胜任手头的工作。</li></ul><p>本文的 <strong>目的</strong>：探讨监控驾驶员的状态以及预测不安全驾驶行为。</p><p>开发一个包括两个阶段的框架的几个问题:监测和预测驾驶员和驾驶行为。</p><h2 id="Driver-drowsiness-measurement"><a href="#Driver-drowsiness-measurement" class="headerlink" title="Driver drowsiness measurement"></a>Driver drowsiness measurement</h2><div class="note primary no-icon"><p>这一节主要是司机困倦状态的监测，从视觉特征和非视觉特征两个角度来讨论驾驶员的行为特征，并且讨论了基于车辆的特征相关的驾驶行为。视觉特征方面，这节详细讨论了与眼睛相关的测量方法，如PERCLOS、呵欠检测以及目前在视觉特征测量中的一些局限性。非视觉特征方面，这节探索用于检测睡意的生理信号。基于车辆的特征，本节描述了方向盘运动和横向位置的标准偏差。 </p></div><p><strong>监测困倦状态的原因</strong></p><p>微睡眠(micro-sleep)的持续时间可以在几秒到30秒甚至更多之间。因此，驾驶员的困倦状态，即从清醒到睡眠的过渡状态，应该被监测。</p><p><img src= "/img/loading.gif" data-lazy-src="/image/pages/002.png" alt="Summary of various features for detecting and predicting driver drowsiness"></p><p>上图是监测司机困倦状态的特征总结。</p><p>驾驶员行为信息包括 <strong>视觉特征</strong>和 <strong>非视觉特征</strong>。</p><p><strong>视觉特征</strong></p><ul><li>闭眼(eye closure)</li><li>眨眼(eye blinking)</li><li>打哈欠(yawning)</li><li>头部姿势(head pose)</li><li>面部表情(facial expression)<br>可以增加的：</li><li>眨眼频率(frequency of eye blinking)：衡量疲劳程度的良好指标</li><li>眼睑张开程度(degree of eyelid opening)：衡量疲劳程度的良好指标</li></ul><p><strong>非视觉特征</strong></p><ul><li>心率(heart rate)</li><li>脉搏率(pulse rate)</li><li>大脑活动(brain activity)。<br>可以增加一些生理信号:</li><li>心电图(electrocardiogram ECG)</li><li>肌电图(electromyogram EMG)</li><li>眼电图(electro-oculogram EoG)</li><li>脑电图(electroencephalogram EEG))</li></ul><p><strong>驾驶行为信息</strong></p><ul><li>车道位置偏差(deviations from lane position)</li><li>车速(vehicle speed)</li><li>转向运动(steering movement)</li><li>加速踏板压力(pressure on the acceleration pedal)等</li></ul><h3 id="Visual-features"><a href="#Visual-features" class="headerlink" title="Visual features"></a>Visual features</h3><div class="note primary no-icon"><p>这一节主要是从视觉特征角度来讨论驾驶员的行为特征，详细讨论了与眼睛相关的测量方法PERCLOS,并介绍了一下目前的打呵欠检测以及目前在视觉特征测量中的一些局限性。</p></div><p>从视觉方面主要是看监测面部动作，面部动作(facial movements)包括下面三个方面：</p><ul><li>眨眼(eye blinking)</li><li>频繁打哈欠(frequent yawning)</li><li>点头或者摆动头(nodding or swinging head)</li></ul><div class="note info no-icon"><p>对于眨眼可以采用PERCLOS方法。</p></div><p><strong>PERCLOS (Percent Eye Closure)</strong></p><ul><li>对司机警觉性水平的可靠和有效的测定</li><li>PERCLOS是驾驶员眼睑闭合时间占瞳孔总时间的80%(或以上)，也反映了眼睑闭合缓慢。？？</li><li>当PERCLOS超过预定的阈值，提出的系统产生瞌睡警告。</li><li>其缺点是，有些情况监测不到：有时试图保持清醒的司机可能睁着眼睛睡着了。</li></ul><p>计算PERCLOS需要提取包括瞳孔面积在内的眼睛区域<br>在提取这些视觉特征方面存在一些限制：合适的照明(proper lighting)</p><p>监测司机是否困倦应该考虑真实情况：</p><ul><li><strong>白天和晚上</strong>：一个简单的CCD或网络相机在白天使用，而红外相机在晚上使用</li><li>司机 <strong>是否戴眼镜</strong>：<ol><li>需要找到合适的近红外(Near IR  NIR)光照波长【一个可能的候选波长是850nm。在真实的汽车环境中，反射的阳光也产生在眼镜的外表面。为了减少反射效果，Jo等[34]使用了带窄带通滤光片的近红外光源，将入射光的波长限制在850nm。这是因为高功率LED照明灯比车内的阳光更强大。】</li><li>用于商业产品如视觉机器[35]的faceLAB。利用被动式摄像机对视频图像进行实时处理，确定各特征的三维位置。该系统能够确定一个精确的3D头部姿态和计算眼睛注视方向。它的优点包括能够很好地应对光线不足的情况，以及司机戴着太阳镜时头部的运动。</li></ol></li></ul><div class="note info no-icon"><p>打哈欠可以通过测量驾驶员口腔轮廓的变化速率和变化量来检测[7,11]。</p></div><div class="note info no-icon"><p>头部姿态估计和头部运动检测(如点头)在监控驾驶员机警性方面也很重要[36,37]</p></div><div class="note info no-icon"><p>此外，司机的面部皱纹出现在眉毛、嘴部和鼻唇沟，这些都是很好的身体信号，表明困倦被抑制了，因此困倦就出现了。</p></div><h3 id="Non-visual-features"><a href="#Non-visual-features" class="headerlink" title="Non-visual features"></a>Non-visual features</h3><div class="note primary no-icon"><p>这一节主要是从非视觉特征角度来讨论驾驶员的行为特征，主要是通过生理信号的检测来识别，并考虑其侵入性特点的局限性。</p></div><p><strong>原因</strong></p><p>非视觉特征或生理信号，如心率和大脑活动，在预测困倦方面是有用的，与视觉特征相比，假阳性更少，因为只有在司机很好地在睡觉的路上，才能从视觉特征判断困倦状态。即基于这些生理信号的困倦预测使我们有可能及时地向困倦的司机发出警告。</p><p><strong>生理信号</strong></p><ul><li>心电图(ECG)<ul><li>从心电图信号中可以提取出心率(HR);心率可以用来检测睡意，因为它在警觉性和睡意状态之间存在显著差异[19,39]。</li><li>心率变异性(HRV)测量每一拍心跳的变化，也可用来检测睡意。随着司机从警觉状态到昏昏欲睡状态，心电图信号中低频与高频的比率逐渐降低[20,40]。</li></ul></li><li>脑电图(EEG)</li><li>肌电图(EMG)</li><li>眼电图(EoG)</li><li>光容积描记(PPG)</li></ul><p><strong>过程</strong></p><ol><li>处理生理信号的一个 <strong>关键问题</strong>是消除真实环境中不可避免的噪声和人为因素。</li><li>在有效滤波之后，采用了快速傅立叶变换(FFT)和离散小波变换(DWT)等特征提取技术。</li><li>然后，利用支持向量机(SVM)、人工神经网络(ANN)、线性判别分析(LDA)等方法对提取出来的特征进行分类[40-43]</li></ol><p><strong>局限性</strong></p><p>优点：检测驾驶员睡意的可靠性和准确性比可见特征高<br>重要局限性：侵入性</p><p><strong>解决方案</strong></p><ul><li>使用无线技术，如Zigbee和Blutooth，通过将电极放置在方向盘或驾驶员座位上，以非侵入性的方式测量生理信号[44,45]。最后，信号由智能手机处理，确定司机瞌睡[46]。然而，由于电极接触不当，这种非侵入式系统与侵入式系统相比精度较低。</li><li>为了获得可靠的驾驶员嗜睡检测结果，人们尝试融合各种测量结果[20,47]。将PERCLOS、ECC和EEG混合用于检测驾驶员嗜睡，其成功率高于单独测量[20]。Cheng等人[47]使用PERCLOS融合、眨眼频率、最大闭合时间和非转向百分比等方法检测睡意。</li></ul><h3 id="Driving-behavior-features"><a href="#Driving-behavior-features" class="headerlink" title="Driving behavior features"></a>Driving behavior features</h3><div class="note primary no-icon"><p>这一节主要是从车辆特征的驾驶行为特征角度，描述了方向盘运动和横向位置的标准偏差</p></div><p>驾驶行为特征或驾驶性能指标包括方向盘运动、车道保持、加速踏板运动和制动等[48-50]。这些特征与车辆类型以及驾驶员在驾驶习惯、驾驶技能和驾驶经验方面的差异性有关。检测驾驶员睡意水平最常用的两种驾驶行为指标是 <strong>方向盘运动和横向位置的标准偏差</strong>。</p><h2 id="Driver-distraction-detection"><a href="#Driver-distraction-detection" class="headerlink" title="Driver distraction detection"></a>Driver distraction detection</h2><div class="note primary no-icon"><p>这一节 描述了一些与驾驶员分心测量相关的问题，特别是头部姿势和注视方向方法。</p></div><p>暂无</p><h2 id="Predicting-unsafe-driving-behavior"><a href="#Predicting-unsafe-driving-behavior" class="headerlink" title="Predicting unsafe driving behavior"></a>Predicting unsafe driving behavior</h2><div class="note primary no-icon"><p>这一节介绍了不安全驾驶行为的预测方法并解释了基于面部表情和汽车动力学的预测方法。</p></div><p>对驾驶员状态、驾驶行为性能和车辆状态的监测对于提高驾驶员主动安全系统的性能是非常重要的。</p><p>驾驶员的状态通过测量困倦、疲劳或压力水平来监测[61-64]。通过分析驾驶速度、方向盘角度、制动和加速等信息，还可以监测驾驶行为、性能和车辆状态[48- 50,65,66]。在检测到困倦或注意力分散后，就会向司机发送警报。</p><p>主动驾驶员安全系统的另一个 <strong>重要问题</strong>是开发一种机制来 <strong>提前预测小事故和大事故</strong>。</p><p><strong>基于面部表情和汽车动力学的预测方法</strong><br>Jabon等人[15]使用面部特征来帮助预测驾驶员事故。他们结合了车辆动力学和驾驶员面部分析来预测事故。</p><p><strong>过程</strong></p><ol><li>首先，对22个原始面部特征进行综合分析。</li><li>然后从一组时域和频域的数值中提取出对事故预测最有价值的统计量，从而实现对重大和轻微事故的预测。</li></ol><p><strong>结果</strong><br>虽然Jabon et al.[15]的实验结果并不是基于真实的道路情况，但已经发现面部特征在事故发生前4秒表现出最准确的预测能力，并且在预测小事故时比预测大事故更有帮助。这是因为对重大事故的预测精度主要来自车辆的特征，而不是面部特征。</p><p><strong>新技术</strong><br>EPFL and PSA Peugeot Citroen[16]正在开发一种技术，以检测司机的分心以及情绪，表明司机不能胜任手头的任务。即，面部表情和肌肉运动在分析司机是否太过分散注意力、太累或甚至太过愤怒而无法安全控制车辆时非常重要。</p><p><strong>局限性</strong><br>虽然面部特征已被证明有助于预测小事故，但其预测效果还有待提高。</p><p>为了更准确地预测事故，有必要捕捉来自驾驶员或驾驶员环境系统其他部分的其他生理信号。在此基础上，可以提出一种新的交通事故预测模型。特别是在构建更广泛、更通用的事故预测模型时，需要考虑不同的参与者群体、交通文化和驾驶环境。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><div class="note primary no-icon"><p>这一节讨论了主动驾驶员安全系统的一些问题：<br>1)检测睡意的混合方法<br>2)安全驾驶的驾驶上下文感知<br>3)需要用来模拟的公共数据集以及真实驾驶条件</p></div><h3 id="Hybrid-measures-for-drowsiness-detection"><a href="#Hybrid-measures-for-drowsiness-detection" class="headerlink" title="Hybrid measures for drowsiness detection"></a>Hybrid measures for drowsiness detection</h3><div class="note primary no-icon"><p>检测睡意的混合方法</p></div><p><strong>目前监测司机睡意的存在的问题</strong></p><ol><li>在驾驶行为和驾驶员行为特征中，驾驶行为有时不能可靠地检测驾驶员的嗜睡。</li><li>驾驶员行为特征优于驾驶行为特征，但视觉特征有时会受到光照条件和驾驶员姿态[34]的限制。</li><li>非视觉特征，如生理特征是可靠和准确的，但其本质是侵入性的。在它们能够在真实的车辆环境中使用之前，应该解决侵入性这个问题。虽然已经开发了一种侵入性较小的ECG测量方法[45]，但EEG和EoG仍然需要以侵入性的方式将电极放置在头皮或眼睛区域。然而，非侵入性的生理信号测量可能在不久的将来发展。</li></ol><p><strong>混合方法</strong></p><p>融合 <strong>视觉</strong>、<strong>生理</strong>和 <strong>驾驶行为特征</strong>的混合测量</p><p>即使在某些传感器失效的情况下，融合方法也能很好地检测出睡意。图4显示了一个用于驱动状态检测的混合测量示例。其中一个问题是在特征级或决策级[20]上开发一种可靠的数据融合方法。</p><p><img src= "/img/loading.gif" data-lazy-src="/image/pages/003.png" alt="用于检测驱动程序状态的混合测量"></p><h3 id="Driving-context-awareness-for-safe-driving"><a href="#Driving-context-awareness-for-safe-driving" class="headerlink" title="Driving context-awareness for safe driving"></a>Driving context-awareness for safe driving</h3><div class="note primary no-icon"><p>安全驾驶的驾驶上下文感知</p></div><p>为了安全驾驶，驾驶上下文感知是必要的，需要有效地探索与驾驶条件和环境相关的各种信息。</p><p>将驾驶上下文划分为全局和局部。</p><ol><li><strong>全局</strong>驾驶上下文是指车辆类型、道路类型、驾驶时间、驾驶环境、路况等等</li><li><strong>局部</strong>(local)驱动上下文指的是驾驶员状态(driver status)。即局部语境与驾驶员的视觉和认知知觉以及驾驶员因分心、嗜睡和/或情绪而导致的视觉和认知知觉的恶化有关。</li></ol><p>发展方向：结合 <strong>驾驶环境</strong>和 <strong>驾驶员状态</strong>的基于驾驶上下文的计算模型。使用这样的模型，注意力分散和嗜睡的检出率将会增加，这将有助于预测不安全驾驶行为。</p><h3 id="Necessity-for-public-data-sets-for-simulation-and-real-driving-conditions"><a href="#Necessity-for-public-data-sets-for-simulation-and-real-driving-conditions" class="headerlink" title="Necessity for public data sets for simulation and real driving conditions"></a>Necessity for public data sets for simulation and real driving conditions</h3><div class="note primary no-icon"><p>需要用来模拟的公共数据集以及真实驾驶条件</p></div><p>在真实的驾驶环境中测试困倦有危险。</p><p><strong>真实驾驶条件的必要性</strong><br>Philp等人[67]发现，由于体验的单调性，在模拟环境中，来自自我评价的反应时间和嗜睡程度比在真实驾驶环境中要高。<br>Engstorm等[68]指出，真实驾驶条件下的生理负荷和转向活性均高于模拟环境。在真实的驾驶条件下，包括灯光和噪音的变化在内的各种因素也会影响驾驶员的注意力。</p><p><strong>没有可用的基准数据集</strong></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>这篇文章回顾了各种可用的方法来确定困倦和分心的司机的状态。通过对驾驶员视觉特征、非视觉特征和驾驶行为行为等驾驶员行为的研究来检测驾驶员困倦。</p><ol><li>PERCLOS、闭眼时间(ECD)、闭眼频率(FEC)是一种基于视觉特征的检测驾驶员睡意的系统。<br>其中，PERCLOS在检测睡意方面表现良好，但存在光照条件等局限性。为了克服这个问题，使用了850nm的IR光源。</li><li>生理信号如ECG、EEG、EoG和PPG信号作为非视觉特征检测驾驶员困倦。尽管生理信号比视觉特征表现出更好的表现，但它们也有一些局限性，尤其是它们的侵入性。为了克服这个问题，应该开发侵入性较小的传感器。目前，ECG信号可以用一种较少干扰的方式捕获。驾驶性能行为如方向盘运动和侧位标准偏差也被用来检测困倦。</li><li>驾驶员注意力分散是通过头部姿势和注视方向来检测的。驾驶员的分心可能会导致更大的车道变化，更慢的对障碍的反应，以及更突然的转向控制。因此，为了开发一个更安全的驾驶员监控系统，我们应该监控驾驶员的分心。</li><li>对于主动驾驶安全系统而言，预测不安全驾驶行为是一种可取的方法。本文解释了基于面部表情和汽车动力学的预测方法。通过面部表情检测驾驶员的情绪，有助于预测驾驶员的驾驶行为。</li><li>最后本文讨论了主动驾驶安全系统未来发展中需要解决的几个问题。它们是a)检测睡意的混合措施，b)安全驾驶的驾驶环境感知，c)模拟和真实驾驶条件的公共数据集的可用性。</li></ol>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> 论文笔记 </tag>
            
            <tag> driving behavior proﬁling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>dataset</title>
      <link href="/posts/60504/"/>
      <url>/posts/60504/</url>
      
        <content type="html"><![CDATA[<h2 id="公开的数据集"><a href="#公开的数据集" class="headerlink" title="公开的数据集"></a>公开的数据集</h2><h3 id="SHRP2"><a href="#SHRP2" class="headerlink" title="SHRP2"></a>SHRP2</h3><h4 id="数据集获取方式"><a href="#数据集获取方式" class="headerlink" title="数据集获取方式"></a>数据集获取方式</h4><p><a href="https://insight.shrp2nds.us/" target="_blank" rel="noopener">https://insight.shrp2nds.us/</a></p><h3 id="Security-dataset"><a href="#Security-dataset" class="headerlink" title="Security dataset"></a>Security dataset</h3><h4 id="数据集获取方式-1"><a href="#数据集获取方式-1" class="headerlink" title="数据集获取方式"></a>数据集获取方式</h4><p><a href="https://ocslab.hksecurity.net/Datasets/driving-dataset" target="_blank" rel="noopener">https://ocslab.hksecurity.net/Datasets/driving-dataset</a></p><h4 id="数据集的描述"><a href="#数据集的描述" class="headerlink" title="数据集的描述"></a>数据集的描述</h4><ul><li><p>Driving time : about 23 hours</p></li><li><p>Driving length : about 46km (round-trip)</p></li><li><p>Driving path : between Korea University and SANGAM World Cup Stadium</p></li><li><p>#of Driver : 10 (A to J classes in the dataset and our paper.) </p></li><li><p>数据收集是在韩国进行的，使用的是起亚汽车公司的一款最新车型。</p></li><li><p>实验设置由城市道路、高速公路和停车位三种类型的四条道路组成，总长度为23公里。</p></li><li><p>城市道路有信号灯和人行横道，而高速公路没有。在停车位上，司机开车要慢，要小心。</p></li><li><p>试验于2015年7月28日开始。时间因素是通过在类似的时区(工作日晚上8点到11点)进行实验来控制的。</p></li><li><p>司机完成了两个来回为一个可靠的分类。每个司机的驾驶数据从A到j。每秒总共捕获94,401条记录，从而生成16.7 MB的数据集。</p></li><li><p>数据通过车载诊断2 (OBD-II)和CarbigsP (OBD-II扫描仪）从车辆的CAN总线上收集。使用的车辆有许多测量传感器和控制传感器，由电子控制单元(ECU)管理。</p></li></ul><h3 id="UAH‑DriveSet"><a href="#UAH‑DriveSet" class="headerlink" title="UAH‑DriveSet"></a>UAH‑DriveSet</h3><h4 id="数据集获取方式-2"><a href="#数据集获取方式-2" class="headerlink" title="数据集获取方式"></a>数据集获取方式</h4><p><a href="http://www.robesafe.uah.es/personal/eduardo.romera/uah-driveset/" target="_blank" rel="noopener">http://www.robesafe.uah.es/personal/eduardo.romera/uah-driveset/</a></p><h4 id="数据集可视化"><a href="#数据集可视化" class="headerlink" title="数据集可视化"></a>数据集可视化</h4><p><a href="https://github.com/Eromera/uah_driveset_reader" target="_blank" rel="noopener">https://github.com/Eromera/uah_driveset_reader</a></p><h4 id="数据集描述"><a href="#数据集描述" class="headerlink" title="数据集描述"></a>数据集描述</h4><ul><li>UAH-DriveSet是由驾驶监控应用DriveSafe在不同环境下的不同测试人员捕获的数据的公共集合。</li><li>数据集由6名不同年龄和车辆的驾驶员收集，其中包括一辆全电动汽车。(具体见下图)</li><li>3个行为(正常,昏昏欲睡和侵略性)进行了在两个不同的路线(高速公路和二级公路)<ul><li>25公里(往返)高速公路的道路通常3车道在每个方向和最大允许速度120公里/小时,</li><li>16公里左右的二级公路,通常一个车道在每个方向和最大允许速度约为90公里/小时。</li></ul></li><li>超过500分钟的自然驾驶相关的原始数据和额外的语义信息,一起旅行的录像。</li></ul><p><img src= "/img/loading.gif" data-lazy-src="/image/pages/001.png" alt="司机和车的列表信息"></p><h4 id="数据集的引用"><a href="#数据集的引用" class="headerlink" title="数据集的引用"></a>数据集的引用</h4><blockquote><p>E. Romera, L.M. Bergasa and R. Arroyo, “Need Data for Driving Behavior Analysis? Presenting the Public UAH-DriveSet”, IEEE International Conference on Intelligent Transportation Systems (ITSC), pp. 387-392, Rio de Janeiro (Brazil), November 2016. <a href="http://www.robesafe.uah.es/personal/eduardo.romera/pdfs/Romera16itsc.pdf" target="_blank" rel="noopener">pdf</a></p></blockquote><h3 id="HciLab-dataset"><a href="#HciLab-dataset" class="headerlink" title="HciLab dataset"></a>HciLab dataset</h3><h4 id="数据集获取方式-3"><a href="#数据集获取方式-3" class="headerlink" title="数据集获取方式"></a>数据集获取方式</h4><p><a href="https://www.hcilab.org/research/hcilab-driving-dataset/." target="_blank" rel="noopener">https://www.hcilab.org/research/hcilab-driving-dataset/.</a></p><h4 id="数据集描述-1"><a href="#数据集描述-1" class="headerlink" title="数据集描述"></a>数据集描述</h4><ul><li>来源自德国斯图加特大学可视化和交互系统研究所hciLab集团</li><li>数据中包含了10名参与者，压缩包数据共37.9MB的大小</li></ul><h4 id="数据集的引用-1"><a href="#数据集的引用-1" class="headerlink" title="数据集的引用"></a>数据集的引用</h4><blockquote><p>Stefan Schneegass, Bastian Pfleging, Nora Broy, Albrecht Schmidt, and Frederik Heinrich. 2013. A data set of real world driving to assess driver workload. In Proceedings of the 5th International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ’13). ACM, New York, NY, USA, 150-157. DOI=10.1145/2516540.2516561 <a href="http://doi.acm.org/10.1145/2516540.2516561" target="_blank" rel="noopener">http://doi.acm.org/10.1145/2516540.2516561</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> dataset </category>
          
      </categories>
      
      
        <tags>
            
            <tag> driving behavior proﬁling </tag>
            
            <tag> dataset </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文调研</title>
      <link href="/posts/%E8%AE%BA%E6%96%87%E8%B0%83%E7%A0%94/"/>
      <url>/posts/%E8%AE%BA%E6%96%87%E8%B0%83%E7%A0%94/</url>
      
        <content type="html"><![CDATA[<h1 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h1><p>总共9篇论文</p><ol><li>Data-driven Robust Scoring Approach for Driver Proﬁling Applications</li><li>Driver Behavior Detection Techniques: A survey</li><li>Driver behavior profiling: An investigation with different smartphone sensors and machine learning</li><li>Driver Behavior Profiling Using Smartphones:  A Low-Cost Platform  for Driver Monitoring</li><li>Driver behaviour proﬁles for road safety analysis</li><li>Investigations on Driver Unique Identification from Smartphone’s GPS Data Alone</li><li>Know Your Master: Driver Proﬁling-based Anti-theft Method</li><li>Various Approaches for Driver and Driving Behavior Monitoring: A Review</li><li>Who is behind the wheel? Driver identification and fingerprinting</li></ol><p>其中涉及的所有公开数据集的下载地址以及详细描述点击<a href="/posts/60504/" title="dataset">dataset</a><br>其中2、3(大概算是)、5、8是综述类文章；6、7、9涉及驾驶员识别</p><h1 id="1-《Data-driven-Robust-Scoring-Approach-for-Driver-Proﬁling-Applications》"><a href="#1-《Data-driven-Robust-Scoring-Approach-for-Driver-Proﬁling-Applications》" class="headerlink" title="1. 《Data-driven Robust Scoring Approach for Driver Proﬁling Applications》"></a>1. 《Data-driven Robust Scoring Approach for Driver Proﬁling Applications》</h1><p>驾驶分析行为：driving behavior proﬁling<br>驾驶员分析过程由两个子过程组成：</p><ol><li>第一种是通过从车载设备(如智能手机和OBDII装置)获取数据来检测某些驾驶行为</li><li>第二种是通过对检测到的行为进行评分的过程来衡量实际的驾驶风险。</li></ol><p><strong>本文的解决方法</strong></p><ul><li>本文提出了一种数据驱动的方法来计算司机的风险分数</li><li>利用SHRP2自然驾驶数据集，这是迄今为止最大的此类数据集。</li><li>训练了两种机器获取算法，即支持向量回归(SVR)和决策树回归(DTR)来反映驾驶员的分数。</li><li>驾驶员的分数是根据预测风险概率的加法逆元来量化的。</li><li>经过数据滤波和预处理，使用代表12种独特驾驶行为和每个驾驶员总驾驶时间的13个预测因子对模型进行训练。验证结果表明，该模型可以准确地预测风险概率。</li></ul><p><del>通常会根据收集到的数据计算每次出行的不同的系数Figures of Merit(FOMs)。</del><br><del>保险公司用来评估风险评分用四种驾驶行为FOMs:制动，超速，加速和转弯行为。</del><br><del>为每个FOM分配不同的权重</del></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>SHRP2自然驾驶研究(NDS)数据集提供了近9000个记录的撞车和接近撞车事件和超过20000个平衡基线事件(即，正常驾驶事件与每个司机的驾驶总数成比例)的大量驾驶上下文数据[5]。</p><p>收集到的数据可以研究危险事件中行为因素的发生率，还包括他们在正常驾驶期间的发生率</p><h2 id="本文的贡献："><a href="#本文的贡献：" class="headerlink" title="本文的贡献："></a>本文的贡献：</h2><ol><li>它提供了一个可靠的数据驱动框架，利用基线、碰撞和接近碰撞事件期间的行为背景信息来预测驾驶员的风险概率。为了实现这一点，12个行为风险预测因子被识别，特征矩阵被制定。驾驶分数用预测风险概率的加性逆表示。</li><li>采用支持向量回归(SVR)和决策树回归(DTR)两种机器学习算法来反映驾驶员的预测风险概率。通过不同的测试样本，比较了两种算法的平均性能和性能一致性。该算法的训练和测试使用了前所未有的数据量，超过2000名司机。</li><li>一个重要的发现是，在适当的采样时间内，只需捕捉少量的事件，就可以准确地预测驾驶风险(平衡的基线事件)。因此，不需要连续采集驾驶数据来确定某一驾驶员的相关风险。这有助于最小化将驾驶数据分流到云服务器所消耗的能量，并最小化预测驾驶风险的计算成本。</li></ol><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><ol><li>本文提出了一种基于数据驱动的健壮的用于驾驶员分析应用程序的风险评分的计算框架。<br>采用预测风险概率表示驾驶员的风险评分</li><li>利用来自SHRP2数据集的2000多名驾驶员的行为驾驶上下文信息和总曝光时间，设计并比较了两种风险预测模型。</li><li>采用一般的分裂法和10倍交叉验证法两种模型训练方法，结果表明，这些模型能够准确地预测风险概率。</li><li>一个重要的发现是，只需在适当的采样时间内捕获少数事件，就可以准确地预测某个司机的驾驶风险。</li><li>SVR模型似乎在所有性能度量上都优于DTR；对于不同的训练/测试样本，DTR的一致性优于SVR</li></ol><p>驾驶员行为分析的两大流派：</p><ol><li>驾驶员行为检测和分类。这包括检测某些事件，如:攻击性加速，攻击性变道等等。</li><li>开发一个评分函数，准确地反映已知的行为[3]，[10]的风险率。</li></ol><p>1多2少，因为评分函数的选择往往是比较主观的。缺乏大规模和可靠的数据集。</p><h2 id="数据集："><a href="#数据集：" class="headerlink" title="数据集："></a>数据集：</h2><p><a href="https://insight.shrp2nds.us/" target="_blank" rel="noopener">SHRP2 NDS Dataset</a></p><p>naturalistic driving (ND) data:自然驾驶数据</p><p>三个重要的优点：</p><ol><li>关于司机在撞车或接近撞车事件前行为的详细信息。</li><li>曝光信息，提供了在正常驾驶事件中不同驾驶行为发生频率的重要信息。</li><li>为进行统计上合理的研究铺平道路的收集数据的数量。</li></ol><h3 id="数据集描述："><a href="#数据集描述：" class="headerlink" title="数据集描述："></a>数据集描述：</h3><p>[SHRP2NDS]<a href="https://insight.shrp2nds.us/" target="_blank" rel="noopener">https://insight.shrp2nds.us/</a></p><p>在SHRP2NDS中，3542名驾驶员在美国6个不同的地点被招募，他们的车辆装备了不显眼的数据采集系统(DASs)，主要包括前向雷达传感器、摄像机、OBD单元来获取车辆的CAN总线信息和全球定位系统(GPS)。这是迄今为止有记录的最大数量的自然驾驶数据。数据还原人员随后能够提取出近9000个由崩溃和接近崩溃组成的风险事件。</p><p>此外，在超过20,000次的正常驾驶事件中随机捕获，为驾驶员提供暴露信息。<br>这些事件被称为平衡基线事件，因为它们的数量与驾驶员的总驾驶时间成正比。<br>VTTI数据分析人员在记录事件期间一共识别了59种驾驶上下文行为属性。<br>这些事件的每种类型的操作定义可以在[5]中找到，具体如下:</p><ol><li>Crash：sd与移动或固定物体(车辆、行人、骑自行车的人、动物等)的任何接触。还包括意外偏离道路。</li><li>Near crash: 任何需要规避动作以避免碰撞的驾驶冲突。</li><li>Balanced baseline events: 选择提供曝光信息的数据次数。它们的长度是21秒，它们的数量与每个司机的总驾驶时间成比例。</li></ol><p>VTTI数据分析人员利用收集到的数据提取并记录了事故发生前/接近事故发生前或基线事件期间的主要驾驶行为。</p><h1 id="2-《Driver-Behavior-Detection-Techniques-A-survey》"><a href="#2-《Driver-Behavior-Detection-Techniques-A-survey》" class="headerlink" title="2. 《Driver Behavior Detection Techniques: A survey》"></a>2. 《Driver Behavior Detection Techniques: A survey》</h1><div class="note danger"><p>综述类文章，后续需要详细看一下，下面还未总结</p></div><p>影响驾驶员行为的因素有疲劳、分心、经验、环境条件、车辆状况等。</p><p><strong>driving style：驾驶风格</strong></p><p>本文讨论了几种被提出的检测驾驶员行为的方法，并确定每种方法的优缺点。</p><p>本文将回顾近年来基于不同参数的驾驶员行为检测方法的研究，以确定适合的驾驶员行为检测方法。<br>用于驾驶员行为检测系统的不同技术，如高级驾驶员辅助系统(ADAS)、模拟器、远程安装摄像头等。</p><p><del>驾驶监控系统技术</del><br><del>驾驶员行为的分类是一个复杂的问题，因为它是一个多维的问题，并且受到驾驶员和交通状态[9]的几个特性的影响。交通状态由一组变量推导，如道路条件、车辆运动学和驾驶员行为[51]。</del><br><del>驾驶风格的评价和识别需要考虑不同的因素，如环境因素、道路状态和车辆[11]、事件分类和识别[12]以及生物生理状态[10]。</del></p><p>In-Vehicle Data Recording Systems 车载数据记录系统<br>Smartphone-based sensing in vehicles 基于智能手机的汽车传感系统<br>real time systems 实时系统</p><p>行为检测方法<br>在[40]中，他们在车上安装了CAN总线来采集数据。采用统计方法:隐马尔可夫模型(HMM)和高斯混合模型(GMM)进行检测。基于一个参数(速度)，他们使用Matlab分析数据，比较不同事件的速度，如变道、超速、停车和稳定驾驶，所有分心和自然驾驶。他们发现HMM比GMM得到的结果更准确。此外，他们还发现，在诸如超车等危险事件中分心驾驶会降低车速。然而，他们在所有事件中都有很高的误报概率。在[41]中，基于CAN-BUS，他们从真实驾驶旅行中收集了不同的数据，他们使用统计方法来检测驾驶行为，如在不可控条件下的均值、中位数和标准差。</p><p>神经网络的优缺点<br>缺点：</p><ol><li>很难分析，因为它们编码的信息不容易解释。</li><li>大多数神经网络不能处理数据点的时间序列，而只能一次计算一个数据向量的输出。在驾驶员行为建模领域，特别是对驾驶动作的预测，数据通常是由不同阶段的序列组成，包含这些时间信息是必不可少的。</li></ol><p>Fuzzy logic</p><p>有其自身的缺点，如信号丢失、需要大内存和长时间处理</p><p>在驾驶监控系统中，传感器通常是关键因素。为了检测驾驶员行为，我们需要自动收集驾驶数据，并应用计算机算法和模型来生成描述驾驶员性能配置文件的分类。在这篇综述中，我们将驾驶行为检测系统一般分为两类车载传感器系统和实时系统。几种技术已被用于检测和识别驾驶员的行为。每种技术都有其优点和缺点。非实时系统技术对驾驶员的训练和反馈非常重要，但不能很好地提高驾驶员的驾驶意识。另一方面，真实的司机监控系统需要多个硬件设备，处理时间长，存储容量大。然而，这些系统有其自身的缺点，如信号丢失、需要大内存和长时间处理。智能手机的发展，可用性和廉价的成本帮助增强和改进驾驶员行为监控系统，克服了以前系统面临的所有障碍。我们可以看到，基于分类问题提出了大量的研究来检测驾驶员的几种行为，并且统计方法给出了一个良好和准确的结果，它为检测问题提供了有价值的见解。此外，我们发现检测系统没有固定的参数，它基于每个系统的目标以及用于收集数据的工具的类型。</p><h1 id="3-《Driver-behavior-profiling-An-investigation-with-different-smartphone-sensors-and-machine-learning》"><a href="#3-《Driver-behavior-profiling-An-investigation-with-different-smartphone-sensors-and-machine-learning》" class="headerlink" title="3. 《Driver behavior profiling: An investigation with different smartphone sensors and machine learning》"></a>3. 《Driver behavior profiling: An investigation with different smartphone sensors and machine learning》</h1><p>驾驶员的行为影响交通安全、燃料/能源消耗和气体排放。司机行为分析试图理解和积极影响司机的行为。通常驾驶员行为分析任务包括驾驶数据的自动收集和计算机模型的应用，以产生一个分类，特征的驾驶员攻击性剖面。虽然采用了不同的传感器和分类方法，但低成本和高性能的解决方案仍是研究的目标。本文对不同的Android智能手机传感器和分类算法进行了研究，以评估哪一种传感器/方法的装配能够使分类具有更高的性能。结果表明，特定的传感器组合和智能方法可以提高分类性能。</p><p><strong>数据集描述</strong></p><ul><li>使用从4个Android智能手机传感器(加速度计、线性加速度、磁强计和陀螺仪)收集的数据，对4个MLAs (BN、MLP、RF和SVM)在检测7种驾驶事件类型中不同配置的性能进行了定量评估。</li><li>在一个有2名驾驶员的真实世界实验中收集了69个此类事件类型的样本。</li></ul><p><strong>实验结果</strong></p><ol><li>滑动窗口尺寸越大表现越好</li><li>陀螺仪和加速计是探测驾驶事件的最佳传感器</li><li>一般来说，使用所有传感器轴比使用单个传感器轴表现更好，除了侵略性的左转事件</li><li>到目前为止，RF是表现最好的MLA，其次是MLP</li><li>前35种组合的性能均令人满意且相当，AUC均值在0.980 ~ 0.999之间变化。</li></ol><p>在未来的工作中，本文希望通过不同的车辆、Android智能手机型号、道路状况、天气和温度来收集更多的驾驶事件样本。本文还希望在评估中增加更多的MLAs，包括基于模糊逻辑和DTW的MLAs。最后，本文打算使用本研究中观察到的最佳评估程序集来开发一个Android智能手机应用程序，该应用程序可以实时检测驾驶事件并计算驾驶员行为概况。</p><h1 id="4-《Driver-Behavior-Profiling-Using-Smartphones-A-Low-Cost-Platform-for-Driver-Monitoring》"><a href="#4-《Driver-Behavior-Profiling-Using-Smartphones-A-Low-Cost-Platform-for-Driver-Monitoring》" class="headerlink" title="4. 《Driver Behavior Profiling Using Smartphones:  A Low-Cost Platform  for Driver Monitoring》"></a>4. 《Driver Behavior Profiling Using Smartphones:  A Low-Cost Platform  for Driver Monitoring》</h1><p><strong>论文题目</strong>：使用智能手机的司机行为分析:一个低成本的司机监控平台</p><p>本文描述了 <strong>SenseFleet</strong>，一个新的移动设备和车辆独立的司机分析和评分应用程序。<br>一个模糊系统被用来计算不同司机的分数使用实时上下文信息，如路线拓扑或天气条件。</p><ul><li>SenseFleet通过融合运动传感器和GPS数据，能够检测加速、刹车、转向和超速事件。</li><li>为了对多个设备和车辆执行事件检测，本文使用了一个校准阶段，该阶段允许调整事件检测算法的模糊集限制。特别是对于超速事件，本文用web服务来获取道路上不同道路的速度限制。</li><li>与现有的解决方案相比，本文提出了一种计分算法，它不仅依赖于事件的数量，而且还考虑上下文信息，如当前的天气条件和时间。</li><li>为了验证平台，本文在不同的条件下使用了该应用程序(即，不同的驾驶员、设备、车辆)，本文使用单一的车辆和路径以及不同的驾驶员以平静和攻击性的方式驾驶进行了一项受控评估研究。</li><li>实验结果表明，SenseFleet能够准确地检测出危险驾驶事件，并能区分激进驾驶者和冷静驾驶者。评分结果与每个驾驶员为他们的实验提供的主观风险度量进行比较。结果显示，SenseFleet的分数在$\pm 1$邻近的司机集群。</li></ul><h1 id="5-《Driver-behaviour-proﬁles-for-road-safety-analysis》"><a href="#5-《Driver-behaviour-proﬁles-for-road-safety-analysis》" class="headerlink" title="5. 《Driver behaviour proﬁles for road safety analysis》"></a>5. 《Driver behaviour proﬁles for road safety analysis》</h1><p><strong>论文题目</strong>：用于道路安全分析的驾驶员行为概况</p><div class="note danger"><p>综述类文章，后续需要详细看一下，下面还未总结</p></div><p>超过90%的道路交通事故是由司机的行为引起的。因此，识别从事不安全驾驶行为的司机有很大的好处。驾驶员行为概况(DBPs)在这里被引入，作为一种评估驾驶员行为作为伤亡事故风险的函数的方法。他们使用全球定位系统(GPS)设备收集的数据，并辅以时空信息。这些配置文件由共同的风险分数组成，可以用来比较驾驶员之间的不同时间和空间。这篇论文详细介绍了这些dbp的发展，并演示了它们在建模影响驾驶员行为的因素时的使用。结果表明，即使控制了道路环境的影响，这些因素仍然是驾驶员行为最强的预测因子，表明不同的时空环境会引起驾驶员的各种心理反应。通过评估行为改变干预措施的影响，保险公司和政府将会对提高道路驾驶司机的风险评估方法和结果感兴趣。</p><h1 id="6-《Investigations-on-Driver-Unique-Identification-from-Smartphone’s-GPS-Data-Alone》"><a href="#6-《Investigations-on-Driver-Unique-Identification-from-Smartphone’s-GPS-Data-Alone》" class="headerlink" title="6. 《Investigations on Driver Unique Identification from Smartphone’s GPS Data Alone》"></a>6. 《Investigations on Driver Unique Identification from Smartphone’s GPS Data Alone》</h1><p><strong>论文题目</strong>：仅从智能手机的GPS数据调查驾驶员的唯一身份</p><p><strong>驾驶员身份识别</strong>一个新兴领域。</p><p>本文提出了一种仅使用智能手机GPS数据进行驾驶员识别的方法。</p><p><strong>数据</strong><br>本文的实验中，使用了两个月的时间收集了38个驾驶员的数据，总行程5万公里。<br>从每一次完成的行程中生成的数据中提取一组137个统计特征，从而量化驾驶员的自然风格。<br>为了进行驾驶员识别，本文将驾驶员分成4 - 5人的自然组，每组以路线邻近度作为分离的决定因素。</p><p><strong>结果</strong></p><ul><li>对于“驾驶员识别”问题，4-5名驾驶员组的平均准确率为82.3%</li><li>某些行为属性如高驾驶技能会影响识别的准确性。</li><li>随机森林分类器提供了最好的结果。</li><li>这些结果对各种利益相关者有很大的影响，因为所提出的方法可以根据驾驶员的自然驾驶风格来识别驾驶员，而这种自然驾驶风格是通过仅从GPS数据中提取的统计参数来量化的。</li></ul><p><strong>结论</strong></p><ul><li>即使只使用智能手机GPS，也有可能以相当高的精度识别司机。</li><li>为了识别出相似的司机需要进行更多的调查。</li><li>如果研究车辆电子控制单元中附加的感觉信息能与gps数据相混淆，那么准确率就会大大提高。</li></ul><h1 id="7-《Know-Your-Master-Driver-Proﬁling-based-Anti-theft-Method》"><a href="#7-《Know-Your-Master-Driver-Proﬁling-based-Anti-theft-Method》" class="headerlink" title="7. 《Know Your Master: Driver Proﬁling-based Anti-theft Method》"></a>7. 《Know Your Master: Driver Proﬁling-based Anti-theft Method》</h1><p><strong>论文题目</strong>：了解你的master:基于司机档案的防盗方法</p><p>本文提出了 <strong>驾驶员验证方法</strong>，该方法利用车辆传感器的测量数据分析驾驶模式。</p><p><strong>驾驶员识别</strong>方向</p><p><strong>数据集</strong></p><p><a href="http://ocslab.hksecurity.net/Datasets/driving-dataset" target="_blank" rel="noopener">CAN data</a></p><ol><li>本文分析司机的真实驾驶数据。且本文从机动车道、城市道和停车场三种道路类型收集数据。10名司机的驾驶数据被反复收集。</li><li>根据难以绕路的行为特征对驾驶员进行分类。为了提高精度，本文丰富了特征集，包括在之前的工作中广泛使用的与制动和加速相关的行为特征，以及从驾驶员行为推导出的机械特征。</li><li>通过特征选择，设计了考虑显著特征的模型。这减少了特征处理的时间开销，提高了检测性能。</li><li>通过导出平均值、中位数和标准差等统计特征来丰富特征集。这使得每个驾驶员的特征值波动的影响最小，最终得到一个可靠的模型。</li><li>处理滑动窗口检测时间点，当检测成为可靠的，并尽快通知车主盗窃事件。</li></ol><h1 id="8-《Various-Approaches-for-Driver-and-Driving-Behavior-Monitoring-A-Review》"><a href="#8-《Various-Approaches-for-Driver-and-Driving-Behavior-Monitoring-A-Review》" class="headerlink" title="8. 《Various Approaches for Driver and Driving Behavior Monitoring: A Review》"></a>8. 《Various Approaches for Driver and Driving Behavior Monitoring: A Review》</h1><p><strong>论文题目</strong>：驾驶员和驾驶行为监控的各种方法:综述</p><p>全文笔记–&gt; <a href="/posts/100001/" title="Various Approaches for Driver and Driving Behavior Monitoring:A Review">Various Approaches for Driver and Driving Behavior Monitoring:A Review</a></p><p>这篇文章回顾了各种可用的方法来确定困倦和分心的司机的状态。通过对驾驶员视觉特征、非视觉特征和驾驶行为行为等驾驶员行为的研究来检测驾驶员困倦。</p><ol><li>PERCLOS、闭眼时间(ECD)、闭眼频率(FEC)是一种基于视觉特征的检测驾驶员睡意的系统。<br>其中，PERCLOS在检测睡意方面表现良好，但存在光照条件等局限性。为了克服这个问题，使用了850nm的IR光源。</li><li>生理信号如ECG、EEG、EoG和PPG信号作为非视觉特征检测驾驶员困倦。尽管生理信号比视觉特征表现出更好的表现，但它们也有一些局限性，尤其是它们的侵入性。为了克服这个问题，应该开发侵入性较小的传感器。目前，ECG信号可以用一种较少干扰的方式捕获。驾驶性能行为如方向盘运动和侧位标准偏差也被用来检测困倦。</li><li>驾驶员注意力分散是通过头部姿势和注视方向来检测的。驾驶员的分心可能会导致更大的车道变化，更慢的对障碍的反应，以及更突然的转向控制。因此，为了开发一个更安全的驾驶员监控系统，我们应该监控驾驶员的分心。</li><li>对于主动驾驶安全系统而言，预测不安全驾驶行为是一种可取的方法。本文解释了基于面部表情和汽车动力学的预测方法。通过面部表情检测驾驶员的情绪，有助于预测驾驶员的驾驶行为。</li><li>最后本文讨论了主动驾驶安全系统未来发展中需要解决的几个问题。它们是a)检测睡意的混合措施，b)安全驾驶的驾驶环境感知，c)模拟和真实驾驶条件的公共数据集的可用性。</li></ol><h1 id="9-《Who-is-behind-the-wheel-Driver-identification-and-fingerprinting》"><a href="#9-《Who-is-behind-the-wheel-Driver-identification-and-fingerprinting》" class="headerlink" title="9. 《Who is behind the wheel? Driver identification and fingerprinting》"></a>9. 《Who is behind the wheel? Driver identification and fingerprinting》</h1><p><strong>论文题目</strong>：谁在开车?驾驶员身份和指纹识别</p><p><strong>驾驶员识别</strong></p><p><strong>研究问题</strong> </p><p>利用车载传感器数据描述驾驶员的驾驶风格</p><p><strong>本文方法</strong><br>本文利用车载传感器测量的真实驾驶数据集来解决驾驶员识别问题，提出了一种基于驾驶模式的时间优化的驾驶员指纹识别方法。</p><p>本文研究了达到预期识别性能所需的最小学习和分类时间。进一步进行特征选择，提取与驾驶员识别最相关的特征。最后，除了与驾驶模式相关的特征外，还显示了驾驶员相关的特征(比如，心率)，进一步提高了识别性能。</p><p><strong>数据集</strong></p><p>本文使用了三个数据集：</p><ol><li><a href="https://ocslab.hksecurity.net/Datasets/driving-dataset" target="_blank" rel="noopener">Security dataset</a></li><li><a href="http://www.robesafe.uah.es/personal/eduardo.romera/uah-driveset/" target="_blank" rel="noopener">UAH‑DriveSet</a></li><li><a href="https://www.hcilab.org/research/hcilab-driving-dataset/." target="_blank" rel="noopener">HciLab dataset</a></li></ol><p><strong>结果表明</strong></p><ul><li>车内网络数据如燃油平衡、制动踏板和方向盘数据对驾驶员的准确识别具有重要意义。</li><li>使用有限数量的传感器数据从受限但明智地选择的一组传感器收集，可以在驾驶的前3分钟内以非常高的准确性识别驾驶员。</li></ul>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> paper </tag>
            
            <tag> driving behavior proﬁling </tag>
            
            <tag> summary </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/hexo-hello-World/"/>
      <url>/posts/hexo-hello-World/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> test </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
